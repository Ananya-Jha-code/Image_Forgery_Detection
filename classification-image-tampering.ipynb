{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nnp.random.seed(2)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.python.keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import model_from_json\nfrom PIL import Image, ImageChops, ImageEnhance\nimport PIL\nimport os\nimport itertools\nfrom tqdm import tqdm\ntf.__version__","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ELA(img_path, quality=90):\n    TEMP = 'ela_' + 'temp.jpg'\n    SCALE = 10\n    original = Image.open(img_path)\n    diff=\"\"\n    try:\n        original.save(TEMP, quality=90)\n        temporary = Image.open(TEMP)\n        diff = ImageChops.difference(original, temporary)\n        \n    except:\n        \n        original.convert('RGB').save(TEMP, quality=90)\n        temporary = Image.open(TEMP)\n        diff = ImageChops.difference(original.convert('RGB'), temporary)\n        \n       \n    d=diff.load()\n    WIDTH, HEIGHT = diff.size\n    for x in range(WIDTH):\n        for y in range(HEIGHT):\n            d[x, y] = tuple(k * SCALE for k in d[x, y])\n#     save_path = dataset_path +'ELA_IMAGES/'\n#     diff.save(save_path+'diff.png')\n    return diff","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_path=\"../input/casia-20-image-tampering-detection-dataset/CASIA2/\"\npath_original = 'Au/'\npath_tampered = 'Tp/'\n# path_mask='CASIA 2 Groundtruth/'\ntotal_original = os.listdir(dataset_path+path_original)\ntotal_tampered = os.listdir(dataset_path+path_tampered)\n# total_mask=os.listdir(dataset_path+path_mask)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pristine_images = []\nfor i in total_original:\n    pristine_images.append(dataset_path+path_original+i)\nfake_images = []\nfor i in total_tampered:\n    fake_images.append(dataset_path+path_tampered+i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(total_tampered),len(fake_images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = (224,224)\noutput_path='./'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.rmdir(output_path+\"resized_images/fake_images/\")\n# os.rmdir(output_path+\"resized_images/pristine_images/\")\n# os.rmdir(output_path+\"resized_images/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_path='./'\nif not os.path.exists(output_path+\"resized_images/\"):\n#     os.makedirs(output_path+\"resized_images/fake_masks/\")\n    os.makedirs(output_path+\"resized_images/fake_images/\")\n    os.makedirs(output_path+\"resized_images/pristine_images/\")\n    height = 224\n    width = 224\n#     p2=output_path+\"resized_images/fake_masks/\"\n    p1=output_path+\"resized_images/fake_images/\"\n    p3=output_path+\"resized_images/pristine_images/\"\n    j=0\n    for fake_image in tqdm(total_tampered):\n        try:\n            if(j%3):\n                j+=1\n                continue\n            img=Image.open(dataset_path+path_tampered + fake_image).convert(\"RGB\")\n            img = img.resize((height, width), PIL.Image.ANTIALIAS)\n            img.save(p1+fake_image)\n            j+=1\n        except:\n            print(\"Encountered Invalid File : \",fake_image)\n        \n    j=0\n    for pristine_image in tqdm(total_original):\n        try:\n            if(j%3):\n                j+=1\n                continue\n            img=Image.open(dataset_path+path_original + pristine_image).convert(\"RGB\")\n            img = img.resize((height, width), PIL.Image.ANTIALIAS)\n            img.save(p3+pristine_image)\n            j+=1\n        except:\n            print(\"Invalid File : \" ,pristine_image)\n        \n        \n        \nelse:\n    print('images resized,path exists')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_fake_image_path=output_path+\"resized_images/fake_images/\"\nresized_pristine_image_path=output_path+\"resized_images/pristine_images/\"\nresized_fake_image=os.listdir(resized_fake_image_path)\nresized_pristine_image=os.listdir(resized_pristine_image_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(resized_pristine_image)\n# os.rmdir(ela_real)\n# os.rmdir(ela_fake)\n# os.rmdir('ELA_IMAGES/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ela_images_path=output_path+'ELA_IMAGES/'\nela_real=ela_images_path+'Au/'\nela_fake=ela_images_path+'Tp/'\nif not os.path.exists(ela_images_path):\n    os.makedirs(ela_images_path)\n    os.mkdir(ela_real)\n    os.mkdir(ela_fake)\n    j=0\n    for i in tqdm(resized_fake_image):\n        ELA(resized_fake_image_path+i).save(ela_fake+i)\n        j+=1\n        if(j==1500):\n            break\n    j=0\n    for i in tqdm(resized_pristine_image):\n        ELA(resized_pristine_image_path+i).save(ela_real+i)\n        j+=1\n        if(j==1500):\n            break\nelse:\n    print('Images are already converted to ELA')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=[]\nY=[]\nj=0\nfor file in tqdm(os.listdir(ela_real)):\n    img=Image.open(ela_real+file)\n    img=np.array(img)\n    X.append(img)\n    Y.append(0)\n    j+=1\n    if(j==1500):\n        break\nj=0\nfor file in tqdm(os.listdir(ela_fake)):\n    img=Image.open(ela_fake+file)\n    img=np.array(img)\n    X.append(img)\n    Y.append(1)\n    j+=1\n    if(j==1500):\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=np.array(X)\nX.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nx_train, x_dev, y_train, y_dev = train_test_split(X, Y, test_size=0.2, random_state=133,shuffle=True)\ny_train=to_categorical(y_train,2)\ny_dev=to_categorical(y_dev,2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2,VGG16\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization,Dropout,MaxPooling2D\nfrom tensorflow.keras.regularizers import l1,l2,l1_l2\n\nbase_model=MobileNetV2(input_shape=(224,224,3),include_top=False,weights='imagenet')\nfor layer in base_model.layers:\n    layer.trainable=False\nx=base_model.output\nx=Conv2D(1024,(3,3),padding='same',activation='relu')(x)\nx=GlobalAveragePooling2D()(x)\nx=Flatten()(x)\nx=Dense(1024,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\nx=Dropout(0.3)(x)\nx=Dense(16,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\nx=Dense(2,activation='softmax')(x)\nmodel=Model(base_model.input,x)\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()\n# base=MobileNetV2()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\nbatch_size = 20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\n# if not os.path.exists('./model_checkpoints'):\n#     os.makedirs('./model_checkpoints')\n# # define callbacks for learning rate scheduling and best checkpoints saving\n# filepath = './model_checkpoints/image_tampering_classification_ela.h5'\n# checkpoint = keras.callbacks.ModelCheckpoint(filepath,monitor='val_accuracy',save_best_only=True,verbose=1)\n\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=13,verbose=1,restore_best_weights=True)\n\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.22, patience = 6, verbose = 1, \n                                              min_delta = 0.0001,min_lr=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(x_train,y_train,\n                 epochs = epochs,\n                validation_data = (x_dev,y_dev),\n                callbacks = [early_stop,reduce_lr],\n                verbose=1,shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save('/kaggle/working/model_casia_run1.h5')\n# model.save_weights('/kaggle/working/model_casia_run1.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_extractor=base_model.predict(x_train)\n\nfeatures = feature_extractor.reshape(feature_extractor.shape[0], -1)\n\nX_for_training = features #This is our X input to RF\n\n#RANDOM FOREST\n#from sklearn.ensemble import RandomForestClassifier\n#model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n\n# Train the model on training data\ny_train_label=np.where(y_train==1)[1]\n\n#XGBOOST\nimport xgboost as xgb\nmodel = xgb.XGBClassifier()\nmodel.fit(X_for_training, y_train_label) #For sklearn no one hot encoding","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nX_test_feature = base_model.predict(x_dev)\nX_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n\n#Now predict using the trained RF model. \nprediction = model.predict(X_test_features)\n#Inverse le transform to get original label back. \n# prediction = le.inverse_transform(prediction)\ny_test=np.where(y_dev==1)[1]\n#Print overall accuracy\nfrom sklearn import metrics\nprint (\"Accuracy = \", metrics.accuracy_score(y_test, prediction))\n\n#Confusion Matrix - verify accuracy of each class\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, prediction)\n#print(cm)\nsns.heatmap(cm, annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=model.predict(X_test_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred[0:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Loss of the model is - \" , model.evaluate(X_test_features,y_test)[0])\n# print(\"Accuracy of the model is - \" , model.evaluate(X_test_features,y_test)[1]*100 , \"%\")\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(x_dev)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_dev,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction","metadata":{}},{"cell_type":"code","source":"class_names = ['real','fake']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_image_path = '../input/casia-20-image-tampering-detection-dataset/CASIA2/Tp/Tp_D_CNN_M_B_nat10139_nat00059_11949.jpg'\nimage = ELA(real_image_path)\nimage=image.resize((224, 224), PIL.Image.ANTIALIAS)\nimage=np.array(image)\nimage = image.reshape(-1, 224, 224, 3)\n# image=np.array(image)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fake_image_path = '../input/casia-20-image-tampering-detection-dataset/CASIA2/Au/Au_ani_00022.jpg'\nimage = ELA(fake_image_path)\nimage=image.resize((224, 224), PIL.Image.ANTIALIAS)\nimage=np.array(image)\nimage = image.reshape(-1, 224, 224, 3)\n# image=np.array(image)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total,correct=0,0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(x_dev)):\n    image=x_dev[i]\n    image=np.array(image)\n    image = image.reshape(-1, 224, 224, 3)\n    y_true=0\n    if(y_dev[i][1]==1):\n        y_true=1\n    y_pred = model.predict(image)\n    y_pred_class = np.argmax(y_pred, axis = 1)[0]\n    total += 1\n    \n    if y_pred_class == y_true:\n            correct += 1        \n    print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n    print(f'Class: {class_names[y_true]}')\n    print('******************')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fake_image = os.listdir('../input/casia-20-image-tampering-detection-dataset/CASIA2/Tp/')\n# correct = 0\n# total = 0\n# for file_name in fake_image:\n#     if file_name.endswith('jpg') or file_name.endswith('png'):\n#         fake_image_path = os.path.join('../input/casia-20-image-tampering-detection-dataset/CASIA2/Tp/', file_name)\n# #         image = prepare_image(fake_image_path)\n#         image = ELA(fake_image_path)\n#         image=image.resize((224, 224), PIL.Image.ANTIALIAS)\n#         image=np.array(image)\n#         image = image.reshape(-1, 224, 224, 3)\n#         y_pred = model.predict(image)\n#         y_pred_class = np.argmax(y_pred, axis = 1)[0]\n#         total += 1\n#         if y_pred_class == 1:\n#             correct += 1\n#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# real_image = os.listdir('../input/casia-20-image-tampering-detection-dataset/CASIA2/Au/')\n# correct_r = 0\n# total_r = 0\n# for file_name in real_image:\n#     if file_name.endswith('jpg') or file_name.endswith('png'):\n#         real_image_path = os.path.join('../input/casia-20-image-tampering-detection-dataset/CASIA2/Au/', file_name)\n#         image = ELA(real_image_path)\n#         image=image.resize((224, 224), PIL.Image.ANTIALIAS)\n#         image=np.array(image)\n#         image = image.reshape(-1, 224, 224, 3)\n#         y_pred = model.predict(image)\n#         y_pred_class = np.argmax(y_pred, axis = 1)[0]\n#         total_r += 1\n#         if y_pred_class == 0:\n#             correct_r += 1\n#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correct += correct_r\n# total += total_r\n# print(f'Total: {total_r}, Correct: {correct_r}, Acc: {correct_r / total_r * 100.0}')\n# print(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save('/kaggle/working/model_casia_run2.h5')\n# model.save_weights('/kaggle/working/model_casia_run1.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"/kaggle/working/model_casia_run.h5\")\nprint(\"Saved model to disk\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}